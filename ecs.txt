ECS:
* a highly scalable, fast, container management service that makes it easy to run, stop, and manage Docker containers on a cluster
* Serverless infrastructure

Task Definitions
  * To prepare your application to run on Amazon ECS, you create a task definition. 
  * The task definition is a text file, in JSON format, that describes one or more containers, 
    up to a maximum of ten, that form your application
  * It can be thought of as a blueprint for your application. 
  * Task definitions specify various parameters for your application.
  * Examples of task definition parameters are 
    - which containers to use, 
    - which launch type to use, 
    - which ports should be opened for your application, 
    - and what data volumes should be used with the containers in the task.
    
  * Eg.
        {
            "family": "webserver",
            "containerDefinitions": [
                {
                    "name": "web",
                    "image": "nginx",
                    "memory": "100",
                    "cpu": "99"
                },
            ],
            "requiresCompatibilities": [
                "FARGATE"
            ],
            "networkMode": "awsvpc",
            "memory": "512",
            "cpu": "256",
        }    
        
Tasks and Scheduling
* A task is the instantiation of a task definition within a cluster.
* After you have created a task definition for your application within Amazon ECS, you can specify the number of tasks that will run on your cluster.
* Each task that uses the Fargate launch type has it's own isolation boundary and does not share the 
  underlying kernel, CPU resources, memory resources, or elastic network interface with another task.
* The Amazon ECS task scheduler is responsible for placing tasks within your cluster.
* There are several different scheduling options available.

Clusters
* When you run tasks using Amazon ECS, you place them on a cluster, which is a logical grouping of resources.
* When using the Fargate launch type with tasks within your cluster, Amazon ECS manages your cluster resources. 
* When using the EC2 launch type, then your clusters are a group of container instances you manage. 
* An Amazon ECS container instance is an Amazon EC2 instance that is running the Amazon ECS container agent. 
* Amazon ECS downloads your container images from a registry that you specify, and runs those images within your cluster.



Services
* Amazon ECS allows you to run and maintain a specified number of instances of a task definition simultaneously in an Amazon ECS cluster. 
* This is called a service. 
* If any of your tasks should fail or stop for any reason, the Amazon ECS service scheduler launches another instance of your task 
  definition to replace it and maintain the desired count of tasks in the service depending on the scheduling strategy used.
* In addition to maintaining the desired count of tasks in your service, you can optionally run your service behind a load balancer. 
* The load balancer distributes traffic across the tasks that are associated with the service.

Service Definition Parameters
* A service definition defines 
  - which task definition to use with your service, 
  - how many instantiations of that task to run, 
  - which load balancers (if any) to associate with your tasks.
  eg:
          {
              "cluster": "",
              "serviceName": "",
              "taskDefinition": "",
              "loadBalancers": [
                  {
                      "targetGroupArn": "",
                      "loadBalancerName": "",
                      "containerName": "",
                      "containerPort": 0
                  }
              ],
              "serviceRegistries": [
                  {
                      "registryArn": "",
                      "port": 0,
                      "containerName": "",
                      "containerPort": 0
                  }
              ],
              "desiredCount": 0,
              "clientToken": "",
              "launchType": "FARGATE",
              "platformVersion": "",
              "role": "",
              "deploymentConfiguration": {
                  "maximumPercent": 0,
                  "minimumHealthyPercent": 0
              },
              "placementConstraints": [
                  {
                      "type": "memberOf",
                      "expression": ""
                  }
              ],
              "placementStrategy": [
                  {
                      "type": "random",
                      "field": ""
                  }
              ],
              "networkConfiguration": {
                  "awsvpcConfiguration": {
                      "subnets": [
                          ""
                      ],
                      "securityGroups": [
                          ""
                      ],
                      "assignPublicIp": "ENABLED",
                      "networkInterfaceOwner": "",
                      "networkInterfaceCredential": ""
                  }
              },
              "healthCheckGracePeriodSeconds": 0,
              "schedulingStrategy": "REPLICA",
              "deploymentController": {
                  "type": "ECS"
              },
              "tags": [
                  {
                      "key": "",
                      "value": ""
                  }
              ],
              "enableECSManagedTags": true,
              "propagateTags": "TASK_DEFINITION"
          }  

Service Scheduler Concepts
* If a task in a service stops, the task is killed and a new task is launched. 
* This process continues until your service reaches the number of desired running tasks based on the scheduling strategy 
  that you specified.
  
  There are two service scheduler strategies available:
  -  Replica
    - The replica scheduling strategy places and maintains the desired number of tasks across your cluster.
  - Daemon
    - The daemon scheduling strategy deploys exactly one task on each active container instance that meets all of the task placement constraints specified in your cluster. 
    - When using this strategy, there is no need to specify a desired number of tasks, a task placement strategy, 
     or use Service Auto Scaling policies.
  






























